{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d2a2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>units_residential</th>\n",
       "      <th>units_commercial</th>\n",
       "      <th>saledate</th>\n",
       "      <th>bldg_age_at_sale_calc</th>\n",
       "      <th>log_saleprice</th>\n",
       "      <th>bct2020</th>\n",
       "      <th>schooldist</th>\n",
       "      <th>council</th>\n",
       "      <th>...</th>\n",
       "      <th>longitude</th>\n",
       "      <th>bin_ltdheight</th>\n",
       "      <th>bin_splitzone</th>\n",
       "      <th>bin_histdist</th>\n",
       "      <th>bin_landmark</th>\n",
       "      <th>far_calc</th>\n",
       "      <th>dist_park</th>\n",
       "      <th>dist_subway</th>\n",
       "      <th>dist_hospital</th>\n",
       "      <th>dist_school</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>738 EAST 6TH STREET</td>\n",
       "      <td>10009.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>117.0</td>\n",
       "      <td>15.137266</td>\n",
       "      <td>1002601.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.977946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.716409</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.001207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27 AVENUE C</td>\n",
       "      <td>10009.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-07-11</td>\n",
       "      <td>107.0</td>\n",
       "      <td>15.470877</td>\n",
       "      <td>1002202.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.981031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.758491</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.007157</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>0.002245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153 AVENUE B</td>\n",
       "      <td>10009.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-07-19</td>\n",
       "      <td>117.0</td>\n",
       "      <td>15.706361</td>\n",
       "      <td>1002800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.979857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.943662</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.010503</td>\n",
       "      <td>0.001740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193 EAST 4TH   STREET</td>\n",
       "      <td>10009.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-11-13</td>\n",
       "      <td>117.0</td>\n",
       "      <td>15.853479</td>\n",
       "      <td>1003200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.984223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.368928</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>0.001944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>327 EAST 3 STREET, 1C</td>\n",
       "      <td>10009.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-03-10</td>\n",
       "      <td>97.0</td>\n",
       "      <td>13.120361</td>\n",
       "      <td>1002601.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.978423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.418462</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>0.005194</td>\n",
       "      <td>0.001071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 address  zipcode  units_residential  units_commercial  \\\n",
       "0    738 EAST 6TH STREET  10009.0               11.0               0.0   \n",
       "1            27 AVENUE C  10009.0               24.0               1.0   \n",
       "2           153 AVENUE B  10009.0                5.0               0.0   \n",
       "3  193 EAST 4TH   STREET  10009.0               11.0               1.0   \n",
       "4  327 EAST 3 STREET, 1C  10009.0                0.0               0.0   \n",
       "\n",
       "     saledate  bldg_age_at_sale_calc  log_saleprice    bct2020  schooldist  \\\n",
       "0  2017-04-03                  117.0      15.137266  1002601.0         1.0   \n",
       "1  2017-07-11                  107.0      15.470877  1002202.0         1.0   \n",
       "2  2017-07-19                  117.0      15.706361  1002800.0         1.0   \n",
       "3  2017-11-13                  117.0      15.853479  1003200.0         1.0   \n",
       "4  2017-03-10                   97.0      13.120361  1002601.0         1.0   \n",
       "\n",
       "   council  ...  longitude  bin_ltdheight  bin_splitzone  bin_histdist  \\\n",
       "0      2.0  ... -73.977946            0.0            1.0           0.0   \n",
       "1      2.0  ... -73.981031            0.0            1.0           0.0   \n",
       "2      2.0  ... -73.979857            0.0            1.0           0.0   \n",
       "3      2.0  ... -73.984223            0.0            1.0           0.0   \n",
       "4      2.0  ... -73.978423            0.0            1.0           0.0   \n",
       "\n",
       "   bin_landmark  far_calc  dist_park  dist_subway  dist_hospital  dist_school  \n",
       "0           0.0  3.716409   0.000879     0.009050       0.007082     0.001207  \n",
       "1           0.0  3.758491   0.000644     0.007157       0.005513     0.002245  \n",
       "2           0.0  3.943662   0.000317     0.004768       0.010503     0.001740  \n",
       "3           0.0  3.368928   0.001198     0.005776       0.009023     0.001944  \n",
       "4           0.0  5.418462   0.000262     0.009351       0.005194     0.001071  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Data/OUTPUT_cleandata/df_dist.csv').drop(columns=['Unnamed: 0', 'block', 'lot', 'block_pluto', 'lot_pluto'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca3f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "\n",
    "df = df.drop(columns=['schooldist', 'council', 'policeprct', 'healthcenterdistrict', 'sanitdistrict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f4f29c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4acaf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bct2020', 'bin_histdist', 'bin_landmark', 'bin_ltdheight',\n",
       "       'bin_splitzone', 'bldg_age_at_sale_calc', 'comarea', 'dist_hospital',\n",
       "       'dist_park', 'dist_school', 'dist_subway', 'factryarea', 'far_calc',\n",
       "       'garagearea', 'healtharea', 'latitude', 'log_saleprice', 'longitude',\n",
       "       'numbldgs', 'numfloors', 'officearea', 'otherarea', 'resarea',\n",
       "       'retailarea', 'saledate', 'strgearea', 'units_commercial',\n",
       "       'units_residential', 'yearalter1', 'yearalter2', 'yearbuilt',\n",
       "       'zipcode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ef69d",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f49915",
   "metadata": {},
   "source": [
    "### Sort chronologically, train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96c0376b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46696, 30)\n",
      "(46696,)\n",
      "(15565, 30)\n",
      "(15565,)\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "\n",
    "#sort values by date\n",
    "df = df.sort_values('saledate')\n",
    "df = df.drop(columns=['saledate'])\n",
    "\n",
    "# drop sale price\n",
    "\n",
    "#subset into X and y\n",
    "X = df.drop('log_saleprice', axis=1)\n",
    "y = df['log_saleprice']\n",
    "\n",
    "#split into train test split\n",
    "train_size = round(len(df)*0.75)\n",
    "X_train = X[:train_size]\n",
    "X_test = X[train_size:]\n",
    "y_train = y[:train_size]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9287e27e",
   "metadata": {},
   "source": [
    "## Run models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bd6ae1",
   "metadata": {},
   "source": [
    "### RF preprocessor, full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c34ba0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "numeric_features_full = X_train.select_dtypes([np.number]).columns.tolist()\n",
    "categorical_features_full = X_train.select_dtypes([object]).columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))])\n",
    "\n",
    "preprocessor_full_rf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features_full),\n",
    "        ('cat', categorical_transformer, categorical_features_full)])\n",
    "\n",
    "preprocess_full_rf = preprocessor_full_rf.fit(X_train) \n",
    "\n",
    "def preprocessor_full_rf(data):\n",
    "    preprocessed_data = preprocess_full_rf.transform(data)\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570bc50c",
   "metadata": {},
   "source": [
    "#### RF, full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad92e65e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Random Forest for feat. selection\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {'max_depth': [10, 20, 30, 40, 50],\n",
    "              'n_estimators': [10, 20, 30, 40, 50]}\n",
    "\n",
    "grid = GridSearchCV(RandomForestRegressor(), param_grid = param_grid, cv=10)\n",
    "\n",
    "grid.fit(preprocessor_full_rf(X_train), y_train)\n",
    "\n",
    "print(\"best median cross-val score: {}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "print(\"test-set score: {}\".format(grid.score(preprocessor_full_rf(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b5b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_forest = RandomForestRegressor(max_depth = grid.best_params_['max_depth'], n_estimators=grid.best_params_['n_estimators']).fit(preprocessor_full_rf(X_train), y_train)\n",
    "\n",
    "forest_1_predictions = best_forest.predict(preprocessor_full_rf(X_test))\n",
    "\n",
    "feature_names = X_train.columns\n",
    "forest_importances = pd.DataFrame(best_forest.feature_importances_, index=feature_names).sort_values([0], ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(forest_importances.index, forest_importances[0])\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature importances from best Random Forest model; max depth {} and n_estimators {}'.format(\n",
    "    grid.best_params_['max_depth'], grid.best_params_['n_estimators']))\n",
    "plt.grid()\n",
    "plt.savefig('OUTPUT_models/featureimportances.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7625fa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_imp_cols = forest_importances.index[:20]\n",
    "\n",
    "X_train_imp = X_train[most_imp_cols]\n",
    "X_test_imp = X_test[most_imp_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2315c40d",
   "metadata": {},
   "source": [
    "### RF preprocessor, subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21db59fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_features_sub = X_train_imp.select_dtypes([np.number]).columns.tolist()\n",
    "categorical_features_sub = X_train_imp.select_dtypes([object]).columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))])\n",
    "\n",
    "preprocessor_sub_rf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features_full),\n",
    "        ('cat', categorical_transformer, categorical_features_full)])\n",
    "\n",
    "preprocess_sub_rf = preprocessor_sub_rf.fit(X_train_imp) \n",
    "\n",
    "def preprocessor_sub_rf(data):\n",
    "    preprocessed_data = preprocess_sub_rf.transform(data)\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc218ba6",
   "metadata": {},
   "source": [
    "#### RF, subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ad817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=20, max_depth=20).fit(preprocessor_sub_rf(X_train_imp), y_train)\n",
    "#param_grid = {'max_depth': [10, 15, 20, 25],\n",
    "              #'n_estimators': [10, 30, 50, 100]}\n",
    "#grid = GridSearchCV(RandomForestRegressor(), param_grid = param_grid, cv=10)\n",
    "\n",
    "print(\"Train set score: {:.5f}\".format(rf.score(preprocessor_sub_rf(X_train_imp), y_train)))\n",
    "print(\"Mean cross-val score for train set: {:.5f}\".format(cross_val_score(rf, preprocessor_sub_rf(X_train_imp), y_train, scoring='r2').mean()))\n",
    "print(\"Test set score: {:.5f}.\".format(rf.score(preprocessor_sub_rf(X_test_imp), y_test)))\n",
    "\n",
    "forest_2_predictions = rf.predict(preprocessor_sub_rf(X_test_imp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63284f6",
   "metadata": {},
   "source": [
    "### OLS preprocessor, full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8739b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#turn columns into categorical variables: zip code, police precinct, school district, etc.\n",
    "#ENSURE COLS ARE OHE: ['policeprct', 'schooldist', 'healthcenterdistrict', 'sanitdistrict', 'council']\n",
    "\n",
    "numeric_features_full = X_train.select_dtypes([np.number]).columns.tolist()\n",
    "\n",
    "categorical_features_full = X_train.select_dtypes([object]).columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor_full_ols = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features_full),\n",
    "        ('cat', categorical_transformer, categorical_features_full)])\n",
    "\n",
    "preprocessor_full_ols = preprocessor_full_ols.fit(X_train) \n",
    "\n",
    "def preprocessor_full_ols(data):\n",
    "    preprocessed_data=preprocessor_full_ols.transform(data)\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab87afc",
   "metadata": {},
   "source": [
    "#### OLS, full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e24507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from statistics import mean\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lr = LinearRegression().fit(preprocessor_full_ols(X_train), y_train)\n",
    "\n",
    "print(\"Train set score: {:.5f}\".format(lr.score(preprocessor_full_ols(X_train), y_train)))\n",
    "print(\"Mean cross-val score for train set: {:.5f}\".format(cross_val_score(lr, preprocessor_full_ols(X_train), y_train, scoring='r2').mean()))\n",
    "print(\"Test set score: {:.5f}.\".format(lr.score(preprocessor_full_ols(X_test), y_test)))\n",
    "\n",
    "ols_1_predictions = lr.predict(preprocessor_full_ols(X_test))\n",
    "\n",
    "#sort results by coefficient size\n",
    "ols_1_results = pd.concat((pd.DataFrame(X_train.columns), pd.DataFrame(lr.coef_)), axis=1)\n",
    "ols_1_results.columns = ['column', 'coef']\n",
    "ols_1_results = ols_1_results.sort_values('coef', ascending=True)\n",
    "\n",
    "#plot figure\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(ols_1_results.column, ols_1_results.coef)\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel('Coefficient size')\n",
    "plt.savefig(\"OUTPUT_models/fullolscoefs.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ece081",
   "metadata": {},
   "source": [
    "### OLS preprocessor, subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd62a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_sub = X_train_imp.select_dtypes([np.number]).columns.tolist()\n",
    "categorical_features_sub = X_train_imp.select_dtypes([object]).columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocess_sub_ols = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features_sub),\n",
    "        ('cat', categorical_transformer, categorical_features_sub)])\n",
    "\n",
    "preprocess_sub_ols = preprocess_sub_ols.fit(X_train_imp) \n",
    "\n",
    "def preprocessor_sub_ols(data):\n",
    "    preprocessed_data = preprocess_sub_ols.transform(data)\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef9fc10",
   "metadata": {},
   "source": [
    "#### OLS, subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4945d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from statistics import mean\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lr = LinearRegression().fit(preprocessor_sub_ols(X_train_imp), y_train)\n",
    "\n",
    "print(\"Train set score: {:.5f}\".format(lr.score(preprocessor_sub_ols(X_train_imp), y_train)))\n",
    "print(\"Mean cross-val score for train set: {:.5f}\".format(cross_val_score(lr, preprocessor_sub_ols(X_train_imp), y_train, scoring='r2').mean()))\n",
    "print(\"Test set score: {:.5f}.\".format(lr.score(preprocessor_sub_ols(X_test_imp), y_test)))\n",
    "\n",
    "ols_2_predictions = lr.predict(preprocessor_sub_ols(X_test_imp))\n",
    "\n",
    "#sort results by coefficient size\n",
    "ols_2_results = pd.concat((pd.DataFrame(X_train_imp.columns), pd.DataFrame(lr.coef_)), axis=1)\n",
    "ols_2_results.columns = ['column', 'coef']\n",
    "ols_2_results = ols_2_results.sort_values('coef', ascending=True)\n",
    "\n",
    "#plot figure\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(ols_2_results.column, ols_2_results.coef)\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel('Coefficient size')\n",
    "plt.savefig(\"OUTPUT_models/subsetcoefs.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3feb61",
   "metadata": {},
   "source": [
    "## Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef0899",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['Model'] = ['RF, all features', 'RF, 20 features', 'OLS, all features', 'OLS, 20 features']\n",
    "results = results.set_index('Model')\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "#RMSE AND %RMSE\n",
    "results['RMSE'] = [math.sqrt(mean_squared_error(forest_1_predictions, y_test)), \n",
    "                  math.sqrt(mean_squared_error(forest_2_predictions, y_test)), \n",
    "                  math.sqrt(mean_squared_error(ols_1_predictions, y_test)), \n",
    "                  math.sqrt(mean_squared_error(ols_2_predictions, y_test))]\n",
    "\n",
    "def percent_rmse(y_true, y_pred):\n",
    "    rmspe = np.sqrt(np.mean(np.square(((y_true - y_pred) / y_true)), axis=0))\n",
    "    return rmspe\n",
    "results['%RMSE'] = [percent_rmse(y_test, forest_1_predictions),\n",
    "                   percent_rmse(y_test, forest_2_predictions),\n",
    "                   percent_rmse(y_test, ols_1_predictions),\n",
    "                   percent_rmse(y_test, ols_2_predictions)]\n",
    "\n",
    "#MAE AND MAPE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "results['MAE'] = [mean_absolute_error(y_test, forest_1_predictions).round(2), \n",
    "                  mean_absolute_error(y_test, forest_2_predictions), \n",
    "                  mean_absolute_error(y_test, ols_1_predictions), \n",
    "                  mean_absolute_error(y_test, ols_2_predictions)]\n",
    "\n",
    "def MAPE(y_true, y_pred):\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true))*100\n",
    "    return mape\n",
    "\n",
    "results['%MAE'] = [MAPE(y_test, forest_1_predictions),\n",
    "                   MAPE(y_test, forest_2_predictions),\n",
    "                   MAPE(y_test, ols_1_predictions),\n",
    "                   MAPE(y_test, ols_2_predictions)]\n",
    "\n",
    "#R2 (COEFFICIENT OF DETERMINATION)\n",
    "from sklearn.metrics import r2_score\n",
    "results['R-squared'] = [r2_score(y_test, forest_1_predictions), \n",
    "                  r2_score(y_test, forest_2_predictions), \n",
    "                  r2_score(y_test, ols_1_predictions), \n",
    "                  r2_score(y_test, ols_2_predictions)]\n",
    "\n",
    "results = results.round(3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ea697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in results.columns:\n",
    "    plt.scatter(results.index, results[i], label=i)\n",
    "plt.legend()\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('Final model performance')\n",
    "plt.savefig('OUTPUT_models/model_performance.png')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6784a83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hit rates\n",
    "y_test_for_hit_rate = list(y_test)\n",
    "hit_rates = pd.DataFrame(index=['RF, all features', 'RF, 20 features', 'OLS, all features', 'OLS, 20 features'], \n",
    "                         columns=['Within 1%', 'Within 5%', 'Within 10%'])\n",
    "predictions = [forest_1_predictions, forest_2_predictions, ols_1_predictions, ols_2_predictions]\n",
    "def predict_hit_rate(y_true, y_pred, margin):\n",
    "    a = 0\n",
    "    rate_tmp = []\n",
    "    for i in y_pred:\n",
    "        if i >= y_true.iloc[a]*(1-margin):\n",
    "            if i >= y_true.iloc[a]*(1+margin):\n",
    "                rate_tmp.append(1)\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            rate_tmp.append(0)\n",
    "        a += 1\n",
    "    return(sum(rate_tmp) / len(rate_tmp))\n",
    "\n",
    "hit_rates['Within 1%']['RF, all features'] = predict_hit_rate(y_test, forest_1_predictions, 0.01)*100\n",
    "hit_rates['Within 1%']['RF, 20 features'] = predict_hit_rate(y_test, forest_2_predictions, 0.01)*100\n",
    "hit_rates['Within 1%']['OLS, all features'] = predict_hit_rate(y_test, ols_1_predictions, 0.01)*100\n",
    "hit_rates['Within 1%']['OLS, 20 features'] = predict_hit_rate(y_test, ols_2_predictions, 0.01)*100\n",
    "hit_rates['Within 5%']['RF, all features'] = predict_hit_rate(y_test, forest_1_predictions, 0.05)*100\n",
    "hit_rates['Within 5%']['RF, 20 features'] = predict_hit_rate(y_test, forest_2_predictions, 0.05)*100\n",
    "hit_rates['Within 5%']['OLS, all features'] = predict_hit_rate(y_test, ols_1_predictions, 0.05)*100\n",
    "hit_rates['Within 5%']['OLS, 20 features'] = predict_hit_rate(y_test, ols_2_predictions, 0.05)*100\n",
    "hit_rates['Within 10%']['RF, all features'] = predict_hit_rate(y_test, forest_1_predictions, 0.10)*100\n",
    "hit_rates['Within 10%']['RF, 20 features'] = predict_hit_rate(y_test, forest_2_predictions, 0.10)*100\n",
    "hit_rates['Within 10%']['OLS, all features'] = predict_hit_rate(y_test, ols_1_predictions, 0.10)*100\n",
    "hit_rates['Within 10%']['OLS, 20 features'] = predict_hit_rate(y_test, ols_2_predictions, 0.10)*100\n",
    "\n",
    "hit_rates.astype(float).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af193be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in hit_rates.columns:\n",
    "    plt.scatter(hit_rates.index, hit_rates[i], label=i)\n",
    "plt.legend()\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Percent of predictions with margin of actuals')\n",
    "plt.title('Model hit rates')\n",
    "plt.savefig('OUTPUT_models/hit_rates.png')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
