{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b533a404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units_residential</th>\n",
       "      <th>units_commercial</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>years_elapsed</th>\n",
       "      <th>log_saleprice</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>yearalter1</th>\n",
       "      <th>yearalter2</th>\n",
       "      <th>numbldgs</th>\n",
       "      <th>...</th>\n",
       "      <th>bin_splitzone</th>\n",
       "      <th>bin_histdist</th>\n",
       "      <th>bin_landmark</th>\n",
       "      <th>dist_park</th>\n",
       "      <th>dist_subway</th>\n",
       "      <th>dist_hospital</th>\n",
       "      <th>dist_school</th>\n",
       "      <th>dist_housingdev</th>\n",
       "      <th>dist_college</th>\n",
       "      <th>dist_museum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>117.0</td>\n",
       "      <td>15.137266</td>\n",
       "      <td>40.722732</td>\n",
       "      <td>-73.977946</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.014467</td>\n",
       "      <td>0.007724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>107.0</td>\n",
       "      <td>15.470877</td>\n",
       "      <td>40.721552</td>\n",
       "      <td>-73.981031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.007157</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.012473</td>\n",
       "      <td>0.004429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>117.0</td>\n",
       "      <td>15.706361</td>\n",
       "      <td>40.726569</td>\n",
       "      <td>-73.979857</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.010503</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.010361</td>\n",
       "      <td>0.008657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>117.0</td>\n",
       "      <td>15.853479</td>\n",
       "      <td>40.724240</td>\n",
       "      <td>-73.984223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.008364</td>\n",
       "      <td>0.004690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>97.0</td>\n",
       "      <td>13.120361</td>\n",
       "      <td>40.720893</td>\n",
       "      <td>-73.978423</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>0.005194</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.015058</td>\n",
       "      <td>0.006714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   units_residential  units_commercial  year_sold  years_elapsed  \\\n",
       "0               11.0               0.0       2017          117.0   \n",
       "1               24.0               1.0       2017          107.0   \n",
       "2                5.0               0.0       2017          117.0   \n",
       "3               11.0               1.0       2017          117.0   \n",
       "4                0.0               0.0       2017           97.0   \n",
       "\n",
       "   log_saleprice   latitude  longitude  yearalter1  yearalter2  numbldgs  ...  \\\n",
       "0      15.137266  40.722732 -73.977946      2017.0         0.0       1.0  ...   \n",
       "1      15.470877  40.721552 -73.981031         0.0         0.0       2.0  ...   \n",
       "2      15.706361  40.726569 -73.979857      1984.0         0.0       1.0  ...   \n",
       "3      15.853479  40.724240 -73.984223         0.0         0.0       1.0  ...   \n",
       "4      13.120361  40.720893 -73.978423      1981.0         0.0       1.0  ...   \n",
       "\n",
       "   bin_splitzone  bin_histdist  bin_landmark  dist_park  dist_subway  \\\n",
       "0            1.0           0.0           0.0   0.000879     0.009050   \n",
       "1            1.0           0.0           0.0   0.000644     0.007157   \n",
       "2            1.0           0.0           0.0   0.000317     0.004768   \n",
       "3            1.0           0.0           0.0   0.001198     0.005776   \n",
       "4            1.0           0.0           0.0   0.000262     0.009351   \n",
       "\n",
       "   dist_hospital  dist_school  dist_housingdev  dist_college  dist_museum  \n",
       "0       0.007082     0.001207         0.000187      0.014467     0.007724  \n",
       "1       0.005513     0.002245         0.001172      0.012473     0.004429  \n",
       "2       0.010503     0.001740         0.000568      0.010361     0.008657  \n",
       "3       0.009023     0.001944         0.001361      0.008364     0.004690  \n",
       "4       0.005194     0.001071         0.000323      0.015058     0.006714  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Data/OUTPUT_cleandata/df_dist.csv').drop(columns='Unnamed: 0')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4edb5d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['units_residential', 'units_commercial', 'year_sold', 'years_elapsed',\n",
       "       'log_saleprice', 'latitude', 'longitude', 'yearalter1', 'yearalter2',\n",
       "       'numbldgs', 'numfloors', 'BCR', 'bin_ltdheight', 'bin_splitzone',\n",
       "       'bin_histdist', 'bin_landmark', 'dist_park', 'dist_subway',\n",
       "       'dist_hospital', 'dist_school', 'dist_housingdev', 'dist_college',\n",
       "       'dist_museum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4ec218",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9813f49e",
   "metadata": {},
   "source": [
    "### Sort chronologically, train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4b86b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52816, 21)\n",
      "(52816,)\n",
      "(9321, 21)\n",
      "(9321,)\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "\n",
    "#sort values by date\n",
    "df = df.sort_values('year_sold')\n",
    "df = df.drop(columns=['year_sold'])\n",
    "\n",
    "# drop sale price\n",
    "\n",
    "#subset into X and y\n",
    "X = df.drop('log_saleprice', axis=1)\n",
    "y = df['log_saleprice']\n",
    "\n",
    "#split into train test split\n",
    "train_size = round(len(df)*0.85)\n",
    "X_train = X[:train_size]\n",
    "X_test = X[train_size:]\n",
    "y_train = y[:train_size]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc23a6b",
   "metadata": {},
   "source": [
    "## Run models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d16e5f",
   "metadata": {},
   "source": [
    "### RF preprocessor, full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "443eae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "numeric_features_full = X_train.select_dtypes([np.number]).columns.tolist()\n",
    "categorical_features_full = X_train.select_dtypes([object]).columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))])\n",
    "\n",
    "preprocessor_full_rf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features_full),\n",
    "        ('cat', categorical_transformer, categorical_features_full)])\n",
    "\n",
    "preprocess_full_rf = preprocessor_full_rf.fit(X_train) \n",
    "\n",
    "def preprocessor_full_rf(data):\n",
    "    preprocessed_data = preprocess_full_rf.transform(data)\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a57359b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "units_residential    float64\n",
       "units_commercial     float64\n",
       "years_elapsed        float64\n",
       "latitude             float64\n",
       "longitude            float64\n",
       "yearalter1           float64\n",
       "yearalter2           float64\n",
       "numbldgs             float64\n",
       "numfloors            float64\n",
       "BCR                  float64\n",
       "bin_ltdheight        float64\n",
       "bin_splitzone        float64\n",
       "bin_histdist         float64\n",
       "bin_landmark         float64\n",
       "dist_park            float64\n",
       "dist_subway          float64\n",
       "dist_hospital        float64\n",
       "dist_school          float64\n",
       "dist_housingdev      float64\n",
       "dist_college         float64\n",
       "dist_museum          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eced2a4",
   "metadata": {},
   "source": [
    "#### RF, full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b2e4b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Random Forest for feat. selection\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {'max_depth': [10, 20, 30, 40, 50, 60, 70],\n",
    "              'n_estimators': [10, 20, 30, 40, 50, 60, 70]}\n",
    "\n",
    "grid = GridSearchCV(RandomForestRegressor(), param_grid = param_grid, scoring='neg_mean_squared_error', cv=10)\n",
    "\n",
    "grid.fit(preprocessor_full_rf(X_train), y_train)\n",
    "\n",
    "print(\"best median cross-val score: {}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "print(\"test-set score: {}\".format(grid.score(preprocessor_full_rf(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbf6676",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "best_forest = RandomForestRegressor(max_depth = grid.best_params_['max_depth'], n_estimators=grid.best_params_['n_estimators']).fit(preprocessor_full_rf(X_train), y_train)\n",
    "\n",
    "forest_1_predictions = best_forest.predict(preprocessor_full_rf(X_test))\n",
    "\n",
    "feature_names = X_train.columns\n",
    "forest_importances = pd.DataFrame(best_forest.feature_importances_, index=feature_names).sort_values([0], ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(forest_importances.index, forest_importances[0])\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance (avg. reduction in MSE due to this feature across all DTs)')\n",
    "plt.title('Feature importances from best Random Forest model; max depth {} and n_estimators {}'.format(\n",
    "    grid.best_params_['max_depth'], grid.best_params_['n_estimators']))\n",
    "plt.grid()\n",
    "plt.savefig('Models/featureimportances.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1932ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_imp_cols = forest_importances.index[:10]\n",
    "\n",
    "X_train_imp = X_train[most_imp_cols]\n",
    "X_test_imp = X_test[most_imp_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f89de8",
   "metadata": {},
   "source": [
    "### RF preprocessor, subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdfd5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_features_sub = X_train_imp.select_dtypes([np.number]).columns.tolist()\n",
    "categorical_features_sub = X_train_imp.select_dtypes([object]).columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))])\n",
    "\n",
    "preprocessor_sub_rf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features_sub),\n",
    "        ('cat', categorical_transformer, categorical_features_sub)])\n",
    "\n",
    "preprocess_sub_rf = preprocessor_sub_rf.fit(X_train_imp) \n",
    "\n",
    "def preprocessor_sub_rf(data):\n",
    "    preprocessed_data = preprocess_sub_rf.transform(data)\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f5946f",
   "metadata": {},
   "source": [
    "#### RF, subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5b0047",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': [10, 20, 30, 40, 50, 60, 70],\n",
    "              'n_estimators': [10, 20, 30, 40, 50, 60, 70]}\n",
    "\n",
    "grid = GridSearchCV(RandomForestRegressor(), param_grid = param_grid, scoring='neg_mean_squared_error', cv=10)\n",
    "\n",
    "grid.fit(preprocessor_sub_rf(X_train_imp), y_train)\n",
    "\n",
    "print(\"best median cross-val score: {}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "print(\"test-set score: {}\".format(grid.score(preprocessor_sub_rf(X_test), y_test)))\n",
    "\n",
    "forest_2_predictions = grid.predict(preprocessor_sub_rf(X_test_imp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b1fdb1",
   "metadata": {},
   "source": [
    "### OLS preprocessor, full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9eed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "numeric_features_full = X_train.select_dtypes([np.number]).columns.tolist()\n",
    "\n",
    "categorical_features_full = X_train.select_dtypes([object]).columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor_full_ols = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features_full),\n",
    "        ('cat', categorical_transformer, categorical_features_full)])\n",
    "\n",
    "preprocessor_full_lr = preprocessor_full_ols.fit(X_train) \n",
    "\n",
    "def preprocessor_full_ols(data):\n",
    "    preprocessed_data = preprocessor_full_lr.transform(data)\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f33cb6e",
   "metadata": {},
   "source": [
    "#### OLS, full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5306398",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from statistics import mean\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lr = LinearRegression().fit(preprocessor_full_ols(X_train), y_train)\n",
    "\n",
    "print(\"Train set score: {:.5f}\".format(lr.score(preprocessor_full_ols(X_train), y_train)))\n",
    "print(\"Mean cross-val score for train set: {:.5f}\".format(cross_val_score(lr, preprocessor_full_ols(X_train), y_train, scoring='r2').mean()))\n",
    "print(\"Test set score: {:.5f}.\".format(lr.score(preprocessor_full_ols(X_test), y_test)))\n",
    "\n",
    "ols_1_predictions = lr.predict(preprocessor_full_ols(X_test))\n",
    "\n",
    "#sort results by coefficient size\n",
    "ols_1_results = pd.concat((pd.DataFrame(X_train.columns), pd.DataFrame(lr.coef_)), axis=1)\n",
    "ols_1_results.columns = ['column', 'coef']\n",
    "ols_1_results = ols_1_results.sort_values('coef', ascending=False, key=abs)\n",
    "\n",
    "#plot figure\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(ols_1_results.column, ols_1_results.coef)\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel('Coefficient size')\n",
    "plt.title('Coefficient sizes, OLS with all features')\n",
    "plt.savefig(\"Models/fullolscoefs.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff2b288",
   "metadata": {},
   "source": [
    "### OLS preprocessor, subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b39a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_sub = X_train_imp.select_dtypes([np.number]).columns.tolist()\n",
    "categorical_features_sub = X_train_imp.select_dtypes([object]).columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocess_sub_ols = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features_sub),\n",
    "        ('cat', categorical_transformer, categorical_features_sub)])\n",
    "\n",
    "preprocess_sub_lr = preprocess_sub_ols.fit(X_train_imp) \n",
    "\n",
    "def preprocessor_sub_ols(data):\n",
    "    preprocessed_data = preprocess_sub_lr.transform(data)\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f66f5c",
   "metadata": {},
   "source": [
    "#### OLS, subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d64b39d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from statistics import mean\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lr = LinearRegression().fit(preprocessor_sub_ols(X_train_imp), y_train)\n",
    "\n",
    "print(\"Train set score: {:.5f}\".format(lr.score(preprocessor_sub_ols(X_train_imp), y_train)))\n",
    "print(\"Mean cross-val score for train set: {:.5f}\".format(cross_val_score(lr, preprocessor_sub_ols(X_train_imp), y_train, scoring='r2').mean()))\n",
    "print(\"Test set score: {:.5f}.\".format(lr.score(preprocessor_sub_ols(X_test_imp), y_test)))\n",
    "\n",
    "ols_2_predictions = lr.predict(preprocessor_sub_ols(X_test_imp))\n",
    "\n",
    "#sort results by coefficient size\n",
    "ols_2_results = pd.concat((pd.DataFrame(X_train_imp.columns), pd.DataFrame(lr.coef_)), axis=1)\n",
    "ols_2_results.columns = ['column', 'coef']\n",
    "ols_2_results = ols_2_results.sort_values('coef', ascending=False, key=abs)\n",
    "\n",
    "#plot figure\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(ols_2_results.column, ols_2_results.coef)\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel('Coefficient size')\n",
    "plt.title('Coefficient size, OLS with 10 top features as determined by RF')\n",
    "plt.savefig(\"Models/subsetcoefs.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f487462a",
   "metadata": {},
   "source": [
    "# Model eval metrics (pt. 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed83078",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tmp = pd.DataFrame(\n",
    "    {'y_test': y_test,\n",
    "     'for_1': forest_1_predictions,\n",
    "     'for_2': forest_2_predictions,\n",
    "     'ols_1': ols_1_predictions,\n",
    "     'ols_2': ols_2_predictions\n",
    "    })\n",
    "\n",
    "results = pd.DataFrame()\n",
    "results['Model'] = ['RF, all features', 'RF, 10 features', 'OLS, all features', 'OLS, 10 features']\n",
    "results = results.set_index('Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fb6484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#R2\n",
    "from sklearn.metrics import r2_score\n",
    "results['R-squared'] = [r2_score(y_test, forest_1_predictions), \n",
    "                  r2_score(y_test, forest_2_predictions), \n",
    "                  r2_score(y_test, ols_1_predictions), \n",
    "                  r2_score(y_test, ols_2_predictions)]\n",
    "\n",
    "#mape\n",
    "def mape_in_res_tmp(col_to_calc):\n",
    "    lst_tmp = (res_tmp[col_to_calc] - res_tmp.y_test)/res_tmp.y_test\n",
    "    sum_lst_tmp = sum(lst_tmp)\n",
    "    mape = 100/len(lst_tmp)*sum_lst_tmp\n",
    "    return mape\n",
    "results['MAPE'] = [mape_in_res_tmp('for_1'), \n",
    "                   mape_in_res_tmp('for_2'),\n",
    "                   mape_in_res_tmp('ols_1'),\n",
    "                   mape_in_res_tmp('ols_2')]\n",
    "\n",
    "#coef of dispersion\n",
    "def cod_in_res_tmp(col_to_calc):\n",
    "    list_of_sales_ratios = res_tmp[col_to_calc]/res_tmp.y_test\n",
    "    med_sr = np.median(list_of_sales_ratios)\n",
    "    in_abs_val = [abs(i-med_sr) for i in list_of_sales_ratios]\n",
    "    par = sum(in_abs_val)/len(res_tmp)\n",
    "    cod = 100/med_sr*par\n",
    "    return cod\n",
    "results['COD'] = [cod_in_res_tmp('for_1'), \n",
    "                   cod_in_res_tmp('for_2'),\n",
    "                   cod_in_res_tmp('ols_1'),\n",
    "                   cod_in_res_tmp('ols_2')]\n",
    "\n",
    "results = results.round(3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6902acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in results.columns[::-1]:\n",
    "    plt.bar(results.index, results[i], label=i)\n",
    "plt.legend()\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('Final model performance')\n",
    "plt.savefig('Models/model_performance.png')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e86ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hit rates\n",
    "hit_rates = pd.DataFrame(index=['RF, all features', 'RF, 10 features', 'OLS, all features', 'OLS, 10 features'], \n",
    "                         columns=['Within 1%', 'Within 5%', 'Within 10%', 'Within 15%', 'Within 20%'])\n",
    "\n",
    "def predict_hit_rate(col_to_use, margin):\n",
    "    in_range = []\n",
    "    res_tmp['low'] = res_tmp.y_test-(res_tmp.y_test*margin)\n",
    "    res_tmp['high'] = res_tmp.y_test+(res_tmp.y_test*margin)\n",
    "    place = 0\n",
    "    for i in res_tmp[col_to_use]:\n",
    "        if i > res_tmp['low'].iloc[place]:\n",
    "            if i < res_tmp['high'].iloc[place]:\n",
    "                in_range.append(1)\n",
    "        place =+ 1\n",
    "    a = len(in_range)\n",
    "    b = len(res_tmp)\n",
    "    c = a/b\n",
    "    return c\n",
    "\n",
    "hit_rates['Within 1%']['RF, all features'] = predict_hit_rate('for_1', 0.01)*100\n",
    "hit_rates['Within 1%']['RF, 10 features'] = predict_hit_rate('for_2', 0.01)*100\n",
    "hit_rates['Within 1%']['OLS, all features'] = predict_hit_rate('ols_1', 0.01)*100\n",
    "hit_rates['Within 1%']['OLS, 10 features'] = predict_hit_rate('ols_2', 0.01)*100\n",
    "hit_rates['Within 5%']['RF, all features'] = predict_hit_rate('for_1', 0.05)*100\n",
    "hit_rates['Within 5%']['RF, 10 features'] = predict_hit_rate('for_2', 0.05)*100\n",
    "hit_rates['Within 5%']['OLS, all features'] = predict_hit_rate('ols_1', 0.05)*100\n",
    "hit_rates['Within 5%']['OLS, 10 features'] = predict_hit_rate('ols_2', 0.05)*100\n",
    "hit_rates['Within 10%']['RF, all features'] = predict_hit_rate('for_1', 0.10)*100\n",
    "hit_rates['Within 10%']['RF, 10 features'] = predict_hit_rate('for_2', 0.10)*100\n",
    "hit_rates['Within 10%']['OLS, all features'] = predict_hit_rate('ols_1', 0.10)*100\n",
    "hit_rates['Within 10%']['OLS, 10 features'] = predict_hit_rate('ols_2', 0.10)*100\n",
    "hit_rates['Within 15%']['RF, all features'] = predict_hit_rate('for_1', 0.15)*100\n",
    "hit_rates['Within 15%']['RF, 10 features'] = predict_hit_rate('for_2', 0.15)*100\n",
    "hit_rates['Within 15%']['OLS, all features'] = predict_hit_rate('ols_1', 0.15)*100\n",
    "hit_rates['Within 15%']['OLS, 10 features'] = predict_hit_rate('ols_2', 0.15)*100\n",
    "hit_rates['Within 20%']['RF, all features'] = predict_hit_rate('for_1', 0.20)*100\n",
    "hit_rates['Within 20%']['RF, 10 features'] = predict_hit_rate('for_2', 0.20)*100\n",
    "hit_rates['Within 20%']['OLS, all features'] = predict_hit_rate('ols_1', 0.20)*100\n",
    "hit_rates['Within 20%']['OLS, 10 features'] = predict_hit_rate('ols_2', 0.20)*100\n",
    "\n",
    "hit_rates.astype(float).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3a28fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in hit_rates.columns:\n",
    "    plt.plot(hit_rates.index, hit_rates[i], label=i)\n",
    "plt.legend()\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Percent of predictions with margin of actuals')\n",
    "plt.title('Model hit rates')\n",
    "plt.savefig('Models/hit_rates.png')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649adf76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "sns.histplot(data=res_tmp[['for_1', 'for_2', 'ols_1', 'ols_2', 'y_test']], bins=1000)\n",
    "plt.xlabel('Ln of sale price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c8c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.boxplot(data=res_tmp[['for_1', 'for_2', 'ols_1', 'ols_2', 'y_test']])\n",
    "plt.xlabel('Prediction model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.regplot(data=res_tmp, x='y_test', y='for_1', label='full_forest')\n",
    "sns.regplot(data=res_tmp, x='y_test', y='for_2',label='sub_forest')\n",
    "sns.regplot(data=res_tmp, x='y_test', y='ols_1',label='full_ols')\n",
    "sns.regplot(data=res_tmp, x='y_test', y='ols_2',label='sub_ols')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656391ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18723e19",
   "metadata": {},
   "source": [
    "# SUNSET Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032f27a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['Model'] = ['RF, all features', 'RF, 10 features', 'OLS, all features', 'OLS, 10 features']\n",
    "results = results.set_index('Model')\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "#RMSE AND %RMSE\n",
    "results['RMSE'] = [math.sqrt(mean_squared_error(forest_1_predictions, y_test)), \n",
    "                  math.sqrt(mean_squared_error(forest_2_predictions, y_test)), \n",
    "                  math.sqrt(mean_squared_error(ols_1_predictions, y_test)), \n",
    "                  math.sqrt(mean_squared_error(ols_2_predictions, y_test))]\n",
    "\n",
    "def percent_rmse(y_true, y_pred):\n",
    "    rmspe = np.sqrt(np.mean(np.square(((y_true - y_pred) / y_true)), axis=0))\n",
    "    return rmspe\n",
    "results['%RMSE'] = [percent_rmse(y_test, forest_1_predictions),\n",
    "                   percent_rmse(y_test, forest_2_predictions),\n",
    "                   percent_rmse(y_test, ols_1_predictions),\n",
    "                   percent_rmse(y_test, ols_2_predictions)]\n",
    "\n",
    "#MAE AND MAPE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "results['MAE'] = [mean_absolute_error(y_test, forest_1_predictions).round(2), \n",
    "                  mean_absolute_error(y_test, forest_2_predictions), \n",
    "                  mean_absolute_error(y_test, ols_1_predictions), \n",
    "                  mean_absolute_error(y_test, ols_2_predictions)]\n",
    "\n",
    "def MAPE(y_true, y_pred):\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true))*100\n",
    "    return mape\n",
    "\n",
    "results['%MAE'] = [MAPE(y_test, forest_1_predictions),\n",
    "                   MAPE(y_test, forest_2_predictions),\n",
    "                   MAPE(y_test, ols_1_predictions),\n",
    "                   MAPE(y_test, ols_2_predictions)]\n",
    "\n",
    "#R2 (COEFFICIENT OF DETERMINATION)\n",
    "from sklearn.metrics import r2_score\n",
    "results['R-squared'] = [r2_score(y_test, forest_1_predictions), \n",
    "                  r2_score(y_test, forest_2_predictions), \n",
    "                  r2_score(y_test, ols_1_predictions), \n",
    "                  r2_score(y_test, ols_2_predictions)]\n",
    "\n",
    "results = results.round(3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47830616",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in results.columns:\n",
    "    plt.bar(results.index, results[i], label=i, alpha=0.2)\n",
    "plt.legend()\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('Final model performance')\n",
    "plt.savefig('Models/model_performance.png')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hit rates\n",
    "y_test_for_hit_rate = list(y_test)\n",
    "hit_rates = pd.DataFrame(index=['RF, all features', 'RF, 10 features', 'OLS, all features', 'OLS, 10 features'], \n",
    "                         columns=['Within 1%', 'Within 5%', 'Within 10%'])\n",
    "predictions = [forest_1_predictions, forest_2_predictions, ols_1_predictions, ols_2_predictions]\n",
    "def predict_hit_rate(y_true, y_pred, margin):\n",
    "    a = 0\n",
    "    rate_tmp = []\n",
    "    for i in y_pred:\n",
    "        if i >= y_true.iloc[a]*(1-margin):\n",
    "            if i >= y_true.iloc[a]*(1+margin):\n",
    "                rate_tmp.append(1)\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            rate_tmp.append(0)\n",
    "        a += 1\n",
    "    return(sum(rate_tmp) / len(rate_tmp))\n",
    "\n",
    "hit_rates['Within 1%']['RF, all features'] = predict_hit_rate(y_test, forest_1_predictions, 0.01)*100\n",
    "hit_rates['Within 1%']['RF, 20 features'] = predict_hit_rate(y_test, forest_2_predictions, 0.01)*100\n",
    "hit_rates['Within 1%']['OLS, all features'] = predict_hit_rate(y_test, ols_1_predictions, 0.01)*100\n",
    "hit_rates['Within 1%']['OLS, 20 features'] = predict_hit_rate(y_test, ols_2_predictions, 0.01)*100\n",
    "hit_rates['Within 5%']['RF, all features'] = predict_hit_rate(y_test, forest_1_predictions, 0.05)*100\n",
    "hit_rates['Within 5%']['RF, 20 features'] = predict_hit_rate(y_test, forest_2_predictions, 0.05)*100\n",
    "hit_rates['Within 5%']['OLS, all features'] = predict_hit_rate(y_test, ols_1_predictions, 0.05)*100\n",
    "hit_rates['Within 5%']['OLS, 20 features'] = predict_hit_rate(y_test, ols_2_predictions, 0.05)*100\n",
    "hit_rates['Within 10%']['RF, all features'] = predict_hit_rate(y_test, forest_1_predictions, 0.10)*100\n",
    "hit_rates['Within 10%']['RF, 20 features'] = predict_hit_rate(y_test, forest_2_predictions, 0.10)*100\n",
    "hit_rates['Within 10%']['OLS, all features'] = predict_hit_rate(y_test, ols_1_predictions, 0.10)*100\n",
    "hit_rates['Within 10%']['OLS, 20 features'] = predict_hit_rate(y_test, ols_2_predictions, 0.10)*100\n",
    "\n",
    "hit_rates.astype(float).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b01336",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in hit_rates.columns:\n",
    "    plt.scatter(hit_rates.index, hit_rates[i], label=i)\n",
    "plt.legend()\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Percent of predictions with margin of actuals')\n",
    "plt.title('Model hit rates')\n",
    "plt.savefig('Models/hit_rates.png')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
